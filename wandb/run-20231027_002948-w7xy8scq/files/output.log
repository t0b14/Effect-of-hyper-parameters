
Epoch[1/100], Loss: 7802.6178:   1%|█▌                                                                                                                                                      | 1/100 [00:00<01:37,  1.01it/s]









Epoch[32/100], Loss: 5462.3233:  32%|████████████████████████████████████████████████                                                                                                      | 32/100 [00:21<00:45,  1.49it/s]
Traceback (most recent call last):
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\main.py", line 15, in <module>
    run(config["experiment"])
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\src\runner.py", line 63, in run
    tm.fit(num_epochs=config["training"]["n_epochs"])
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\src\training\training_abstractbaseclass.py", line 88, in fit
    out, loss, h_1 = self.step(partial_in, partial_tar, h_1, gradients=gradients)
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\src\training\training_abstractbaseclass.py", line 163, in step
    loss.backward()
  File "C:\Users\tobia\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "C:\Users\tobia\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\autograd\__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt