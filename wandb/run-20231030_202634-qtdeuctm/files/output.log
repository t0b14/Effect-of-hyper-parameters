
  0%|                                                                                                                                                                                              | 0/2500 [00:00<?, ?it/s]






















Epoch[61/2500], Loss: 3718.7561:   2%|███▌                                                                                                                                                | 61/2500 [00:47<31:21,  1.30it/s]
Traceback (most recent call last):
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\main.py", line 15, in <module>
    run(config["experiment"])
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\src\runner.py", line 62, in run
    tm.fit(num_epochs=config["training"]["n_epochs"])
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\src\training\training_abstractbaseclass.py", line 101, in fit
    out, loss, h_1 = self.step(partial_in, partial_tar, h_1, gradients=gradients)
  File "C:\Users\tobia\Documents\GitHub\RNN_Tobia_Simmler\src\training\training_abstractbaseclass.py", line 176, in step
    loss.backward()
  File "C:\Users\tobia\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "C:\Users\tobia\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\autograd\__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt